---
apiVersion: v1
kind: Namespace
metadata:
  name: observability
  labels:
    pod-security.kubernetes.io/audit: privileged
    pod-security.kubernetes.io/enforce: privileged
    pod-security.kubernetes.io/warn: privileged
---
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: open-telemetry
  namespace: observability
spec:
  url: https://open-telemetry.github.io/opentelemetry-helm-charts
  interval: 1h
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: opentelemetry-operator
  namespace: observability
spec:
  interval: 1h
  chart:
    spec:
      chart: opentelemetry-operator
      sourceRef:
        kind: HelmRepository
        name: open-telemetry
        namespace: observability
  install:
    createNamespace: true
  values:
    manager:
      collectorImage:
        repository: otel/opentelemetry-collector-k8s
    admissionWebhooks:
      certManager:
        enabled: true
      autoGenerateCert:
        enabled: true
---
apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: observability
spec:
  selector:
    app: lgtm
  ports:
    - name: grafana
      protocol: TCP
      port: 3000
      targetPort: 3000
    - name: otel-grpc
      protocol: TCP
      port: 4317
      targetPort: 4317
    - name: otel-http
      protocol: TCP
      port: 4318
      targetPort: 4318
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: lgtm-observability
  namespace: observability
spec:
  storageClassName: simple-and-fast-block
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: lgtm
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: lgtm
  template:
    metadata:
      labels:
        app: lgtm
    spec:
      containers:
        - name: lgtm
          image: grafana/otel-lgtm:latest
          imagePullPolicy: Always
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "6Gi"
              cpu: "2"
          ports:
            - containerPort: 3000
            - containerPort: 4317
            - containerPort: 4318
          readinessProbe:
            exec:
              command:
                - cat
                - /tmp/ready
          volumeMounts:
            - name: obs-storage
              mountPath: /data/tempo
            - name: obs-storage
              mountPath: /data/grafana
            - name: obs-storage
              mountPath: /data/loki
            - name: obs-storage
              mountPath: /loki
            - name: obs-storage
              mountPath: /data/prometheus
      volumes:
        - name: obs-storage
          persistentVolumeClaim:
            claimName: lgtm-observability
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-hostfs-daemonset
  namespace: observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-kubelet
rules:
  - apiGroups: ['']
    resources: ['nodes/stats']
    verbs: ['get', 'watch', 'list']
  - apiGroups: [""]
    resources: ["nodes/proxy"]
    verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-kubelet-binding
subjects:
  - kind: ServiceAccount
    name: otel-hostfs-daemonset
    namespace: observability
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-kubelet
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-host-agent
  namespace: observability
spec:
  managementState: managed
  serviceAccount: otel-hostfs-daemonset
  mode: daemonset
  hostNetwork: true
  volumeMounts:
    - mountPath: /hostfs
      name: host
      readOnly: true
  volumes:
    - name: host
      hostPath:
        path: /
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  config:
    receivers:
      prometheus/kepler:
        config:
          scrape_configs:
            - job_name: kepler-metrics
              scrape_interval: 20s
              scrape_timeout: 10s
              static_configs:
                - targets:
                    - "localhost:9102"
      hostmetrics:
        collection_interval: 30s
        scrapers:
          cpu:
            metrics:
              system.cpu.logical.count:
                enabled: true
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
              system.memory.limit:
                enabled: true
          load: {}
          disk: {}
          filesystem:
            metrics:
              system.filesystem.utilization:
                enabled: true
          network: {}
          paging: {}
          processes: {}
          process:
            mute_process_user_error: true
            metrics:
              process.cpu.utilization:
                enabled: true
              process.memory.utilization:
                enabled: true
              process.threads:
                enabled: true
              process.paging.faults:
                enabled: true
      kubeletstats:
        collection_interval: 30s
        auth_type: "serviceAccount"
        endpoint: "https://${env:K8S_NODE_NAME}:10250"
        insecure_skip_verify: true
      filelog:
        include_file_path: true
        include:
          - /hostfs/var/log/pods/*/*/*.log
        operators:
          - id: container-parser
            type: container
    processors:
      attributes/loki:
        actions:
         - action: insert
           key: log_file_name
           from_attribute: log.file.name
         - action: insert
           key: loki.attribute.labels
           value: log_file_name
      resourcedetection/system:
        detectors: ["system"]
        system:
          hostname_sources: ["os"]
      attributes:
        actions:
          - key: service.namespace
            action: upsert
            value: agent
          - key: service.name
            action: upsert
            value: otel-host-agent
      transform:
        metric_statements:
          - context: datapoint
            statements:
              - set(attributes["host.name"], resource.attributes["host.name"])
              - set(attributes["process.command"], resource.attributes["process.command"])
              - set(attributes["process.command_line"], resource.attributes["process.command_line"])
              - set(attributes["process.executable.name"], resource.attributes["process.executable.name"])
              - set(attributes["process.executable.path"], resource.attributes["process.executable.path"])
              - set(attributes["process.owner"], resource.attributes["process.owner"])
              - set(attributes["process.parent_pid"], resource.attributes["process.parent_pid"])
              - set(attributes["process.pid"], resource.attributes["process.pid"])
      batch: {}
      resource:
        attributes:
          - action: upsert
            key: service.namespace
            value: agent
    connectors:
      count: {}
    exporters:
      otlp:
        endpoint: backend.observability:4317
        tls:
          insecure: true

    service:
      telemetry:
        traces:
          processors:
            - batch:
                schedule_delay: 1000
                exporter:
                  otlp:
                    endpoint: http://backend.observability:4317
                    protocol: grpc/protobuf
        metrics:
          level: detailed
          readers:
            - periodic:
                exporter:
                  otlp:
                    endpoint: http://backend.observability:4317
                    protocol: grpc/protobuf
      pipelines:
        metrics:
          receivers: [prometheus/kepler, hostmetrics, kubeletstats]
          processors: [attributes, resourcedetection/system, transform, batch]
          exporters: [otlp, count]
        metrics/count:
          receivers: [count]
          processors: [batch]
          exporters: [otlp]
        logs:
          receivers: [filelog]
          processors: [attributes/loki, resourcedetection/system, batch]
          exporters: [otlp, count]

---
apiVersion: v1
kind: Service
metadata:
  name: ingest
  namespace: observability
spec:
  selector:
    app.kubernetes.io/name: otel-host-agent-collector
  ports:
    - name: otel-grpc
      protocol: TCP
      port: 4317
      targetPort: 4317
    - name: otel-http
      protocol: TCP
      port: 4318
      targetPort: 4318
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: lgtm
  namespace: observability
spec:
  ingressClassName: nginx
  rules:
  - host: observability.homelab
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: backend
            port:
              number: 3000
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: lgtm-tailscale
  namespace: observability
spec:
  defaultBackend:
    service:
      name: backend
      port:
        number: 3000
  ingressClassName: tailscale
  tls:
    - hosts:
        - observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: podmonitor-servicemonitor-lister
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  - nodes/metrics
  - services
  - endpoints
  - namespaces
  - configmaps
  verbs:
  - get
  - watch
  - list
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - watch
  - list
- nonResourceURLs:
  - /metrics
  - /metrics/cadvisor
  verbs:
  - get
- apiGroups:
  - monitoring.coreos.com
  resources:
  - servicemonitors
  - podmonitors
  - scrapeconfigs
  - probes
  verbs:
  - '*'
- apiGroups:
  - discovery.k8s.io
  resources:
    - endpointslices
  verbs:
    - get
    - list
    - watch
- apiGroups:
    - ""
  resources:
  - namespaces
  verbs:
    - get
    - list
    - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prom-collector-podmonitor-servicemonitor-lister
subjects:
- kind: ServiceAccount
  name: prom-collector
  namespace: observability
roleRef:
  kind: ClusterRole
  name: podmonitor-servicemonitor-lister
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prom-collector
subjects:
  - kind: ServiceAccount
    name: prom-collector
    namespace: observability
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-monitoring-view
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: prom
  namespace: observability
spec:
  managementState: managed
  mode: statefulset
  targetAllocator:
    enabled: true
    serviceAccount: prom-collector
    prometheusCR:
      enabled: true
      podMonitorSelector: {}
      serviceMonitorSelector: {}
  config:
    exporters:
      otlp:
        endpoint: backend.observability:4317
        tls:
          insecure: true

    receivers:
      prometheus:
        config:
          scrape_configs:
          - job_name: 'otel-ta-collector'
            scrape_interval: 5s
            static_configs:
            - targets: [ '0.0.0.0:8888' ]
    service:
      telemetry:
        metrics:
          address: ":8888"
      pipelines:
        metrics:
          receivers: [prometheus]
          exporters: [otlp]
